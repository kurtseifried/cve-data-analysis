#!/usr/bin/env python3

# Import necessary libraries
import os
import csv
import argparse
from datetime import datetime
from collections import defaultdict

def read_csv_files_in_directory(directory):
    """
    Read all CSV files in the specified directory and return their contents as a list of dictionaries.
    Each dictionary represents a row from the CSV files.

    The CSV files are expected to contain data about assigners and their published entries.
    Key fields include:
    - assignerShortName: A unique identifier for each assigner
    - datePublished: The date when an entry was published
    """
    data = []
    for filename in os.listdir(directory):
        if filename.endswith(".csv"):
            filepath = os.path.join(directory, filename)
            with open(filepath, mode='r', newline='') as file:
                reader = csv.DictReader(file)
                for row in reader:
                    data.append(row)
    return data

def generate_month_list(start, end):
    """
    Generate a list of months between start and end dates in 'YYYY-MM' format.
    """
    months = []
    current = start
    while current <= end:
        months.append(current.strftime('%Y-%m'))
        if current.month == 12:
            current = current.replace(year=current.year + 1, month=1)
        else:
            current = current.replace(month=current.month + 1)
    return months

def generate_year_list(start, end):
    """
    Generate a list of years between start and end dates.
    """
    years = []
    for year in range(start.year, end.year + 1):
        years.append(str(year))
    return years

def analyze_assigner_data(data):
    """
    Analyze the data for each assigner and calculate various statistics.

    This function processes the following data for each assigner:
    - Number of entries published
    - Dates of publications
    - Monthly and yearly publication counts
    - First and last publication dates
    - Years active and average entries per year
    """
    # Set the date range for analysis
    start_date = datetime(1999, 1, 1)
    end_date = datetime(2024, 6, 1)
    month_list = generate_month_list(start_date, end_date)
    year_list = generate_year_list(start_date, end_date)

    # Initialize a defaultdict to store information for each assigner
    assigner_info = defaultdict(lambda: {
        'dates': [],
        'monthly_counts': defaultdict(int),
        'yearly_counts': defaultdict(int),
        'monthly_totals': {month: 0 for month in month_list},
        'yearly_totals': {year: 0 for year in year_list}
    })

    # Process each row of data
    for row in data:
        # Extract the assigner's short name and publication date
        assigner = row['assignerShortName']
        date_published = row['datePublished']
        
        if date_published != 'N/A':
            # Clean and parse the date
            # Remove 'Z' if present (indicates UTC time)
            if date_published.endswith('Z'):
                date_published = date_published[:-1]
            # Remove time information if present
            date_published = date_published.split('T')[0]
            # Convert string to datetime.date object
            date_published = datetime.strptime(date_published, '%Y-%m-%d').date()
            
            # Update assigner information
            assigner_info[assigner]['dates'].append(date_published)
            month_key = date_published.strftime('%Y-%m')
            year_key = date_published.year
            # Increment monthly and yearly counts for this publication
            assigner_info[assigner]['monthly_counts'][month_key] += 1
            assigner_info[assigner]['yearly_counts'][year_key] += 1

    # Calculate statistics for each assigner
    results = []
    for assigner, info in assigner_info.items():
        dates = sorted(info['dates'])
        first_date = dates[0].strftime('%Y-%m-%d') if dates else 'N/A'
        last_date = dates[-1].strftime('%Y-%m-%d') if dates else 'N/A'
        monthly_counts = info['monthly_counts']
        yearly_counts = info['yearly_counts']
        
        # Calculate yearly statistics
        max_entries_year = max(yearly_counts.values()) if yearly_counts else 0
        min_entries_year = min(yearly_counts.values()) if yearly_counts else 0
        avg_entries_year = round(sum(yearly_counts.values()) / len(yearly_counts), 2) if yearly_counts else 0.00
        
        # Update monthly and yearly totals
        # This creates a complete record for all months/years in the range, even if no entries were published
        for month in month_list:
            info['monthly_totals'][month] = monthly_counts[month]
        for year in year_list:
            info['yearly_totals'][year] = yearly_counts[int(year)]

        # Calculate years active and average entries per year
        if first_date != 'N/A' and last_date != 'N/A':
            years_active = round((datetime.strptime(last_date, '%Y-%m-%d') - datetime.strptime(first_date, '%Y-%m-%d')).days / 365.25, 2)
            years_active_average = round(len(dates) / years_active, 2) if years_active != 0 else 0.00
        else:
            years_active = 'N/A'
            years_active_average = 'N/A'

        # Append results for this assigner
        results.append({
            'assignerShortName': assigner,
            'totalEntries': len(dates),
            'maxEntriesYear': max_entries_year,
            'minEntriesYear': min_entries_year,
            'avgEntriesYear': avg_entries_year,
            'firstDatePublished': first_date,
            'lastDatePublished': last_date,
            'yearsActive': years_active,
            'yearsActiveAverage': years_active_average,
            'monthlyTotals': info['monthly_totals'],
            'yearlyTotals': info['yearly_totals']
        })

    return results, month_list, year_list

def save_to_csv(results, month_list, year_list, output_file):
    """
    Save the analysis results to a CSV file.
    """
    with open(output_file, mode='w', newline='') as file:
        writer = csv.writer(file)
        # Write header
        header = [
            'assignerShortName', 'totalEntries', 'maxEntriesYear', 'minEntriesYear',
            'avgEntriesYear', 'firstDatePublished', 'lastDatePublished', 'yearsActive',
            'yearsActiveAverage'
        ] + month_list + year_list
        writer.writerow(header)
        
        # Write data for each assigner
        for result in results:
            row = [
                result['assignerShortName'],
                result['totalEntries'],
                result['maxEntriesYear'],
                result['minEntriesYear'],
                f"{result['avgEntriesYear']:.2f}",
                result['firstDatePublished'],
                result['lastDatePublished'],
                f"{result['yearsActive']:.2f}" if result['yearsActive'] != 'N/A' else 'N/A',
                f"{result['yearsActiveAverage']:.2f}" if result['yearsActiveAverage'] != 'N/A' else 'N/A'
            ] + [result['monthlyTotals'][month] for month in month_list] + [result['yearlyTotals'][year] for year in year_list]
            writer.writerow(row)

def main():
    """
    Main function to run the script.
    """
    # Set up command-line argument parsing
    parser = argparse.ArgumentParser(description="Analyze CSV files and collect information per assignerShortName.")
    parser.add_argument("directory", type=str, help="The directory containing the CSV files.")
    parser.add_argument("output_file", type=str, help="The output CSV file.")
    args = parser.parse_args()

    # Read CSV files, analyze data, and save results
    csv_data = read_csv_files_in_directory(args.directory)
    results, month_list, year_list = analyze_assigner_data(csv_data)
    save_to_csv(results, month_list, year_list, args.output_file)

if __name__ == "__main__":
    main()
    
